# Unit 1: Python basics

# Lecture 1: Intro to Python

---
---
## 1.0 Intro

### Given a new challenge, how can we get the computer to solve it for us?
---

> How can we describe the *stages* we want to use to get this done in such a manner that we don't have to do it ourselves?

This is the notion of algorithmic/computational thinking!

> If we want the computer to compute something for us, infer some new knowledge for us, we have to think about how we're going to represent that knowledge  
We do this with *data structures*

We want it to infer or find new information for us, and there are standard tools for making that happen:
- iteration
- recursion

Also a big part of what we want the computer to do is deal with things in a manner that we can see and understand as people.
We're going to use the notion of abstraction to capture elements, treat them as if they were primitives, and reuse them.
- this naturally leads to the idea of *modularization*:
    - creating *modules*, *tokens*, and *elements* that we can stitch together to come up with solutions to problems in interesting ways
    - organizing and modularizing systems using objects, classes, and methods
    - abstraction of *procedures* and *data types*

Once we start learning how to build and think with algorithms, we're going to see that there are **standard classes** of algorithms that will help us solve common problems like **searching** and **sorting**.
Different algorithms have different costs:
- i.e. we'll reason about the expense of doing something a particular way and better ways of finding a solution to different problems


---
### Fundamentally, a computer only does two things:
---

- performs calculations
    - somewhere in the order of a billion per second (two operations in the time it takes light to travel one foot)
- remembers things
    - up to hundreds of gigabytes of storage per device (about 1.5 million books of standard length)


---
### What kind of calculations does a computer do, then?
---

- every computer comes with a set of built-in operations
    - these are typically primitive arithmetic operations (such as addition, subtraction, multiplication, and division) and simple logic operations (such as comparing true and false values)

If that were all we had, it'd be very painful to try to solve complex problems!
- what we, the programmer, want to do instead is define *new* calculations/operations: i.e. things we can create and give to the computer so that it can abstract them, encapsulate them, and treat them as if they were primitives

In summary, then, we can do primitive operations very quickly.  Is that enough?  It might be in some cases.  Still, even with the speed of modern computers, we need to be able to think carefully, cleverly, and algorithmically if we want to do something more.

---
### Simple calulations enough?  Storage enough?
---

Searching the worldwide web
- 45B pages on the worldwide web, 100 words per page
    - takes about 10 operations per page to find whether or not that word is on the page
        - need **5.2 days** to find something with brute force search, then

Playing chess
- about 35 moves for every possible setting on the chess board
    - suppose we want to look ahead 6 moves to decide what course of action you'd like to take to beat your opponent
        - this means we have about 1.8B boards to check
            - assuming 100 operations/choice, it will take us about 30 minutes to decide each move ... probably too slow!

These examples show that, even with fast computers, we *need* cleverness and algorithmic thinking to take those simple calculations and turn them into something more powerful.

If you're then to ask why we can't simply pre-compute and look up answers...
- playing chess, again, we know that experts suggest there are 10^123 different possible games that could exist
    - to put that into context, there are only 10^80 *atoms* in the observable universe
        - we simply cannot store data of this magnitude

So, assuming we can couple the amazing speed and storage capabilities with super clever algorithms, does a modern computer *still* have limitations?  Of course!
- some problems are still too complex to solve in a *reasonable timespan*:
    - accurate weather predictions at a local scale
    - cracking encryption schemes (this is an example of limitations working in our favor)
- some problems are fundamentally impossible to compute:
    - classic Turing halting problem: predicting whether a piece of code will always halt with an answer for any input is impossible

---
---
## 1.1 Knowledge

So, as programmers, what do we want our computers to do for us?  
We want them to compute something for us, of course!  

But what's the knowledge that it's going to use to do that computation?

Need to make a distinction, dividing knowledge into two types:
- declarative knowledge
- imperative knowledge

> declarative knowledge
: a statement of facts (ex. "there is candy taped to the underside of a chair in the lecture hall")

This doesn't tell you where to look for it, it's simply a statement of fact.  You would have to either search in parallel by having everyone reach under their own seat at once or searching the lecture hall seat by seat.  

> imperative knowledge
: a recipe or *"how-to"* knowledge (ex. "face a certain side of the room, count three rows up, start from middle section's left side, count 1 chair to the right, reach under chair, and find candy")

By contrast, this is a very mechanical sequence of steps to find a solution or get things done.

Both are important, but it's primarily imperative knowledge that we'll use to get the computer to do things for us.

---
### A numerical example:
---

Suppose we want to compute the square root of some integer.  
Here's a statement of fact:  
- the square root of the number `x` is `y` such that `y*y` is equal to `x`.

Does this tell us how to find the square root?  Not really, but if someone gives us a good guess, we can at least use this to check.  Still, it doesn't help us to find anything.  

So here, instead, is a very old example of imperative knowledge that can be attributed to Heron of ancient Alexandria in the 2nd century B.C. (although it's suggested that it may even predate that) for finding a square root:
> 1. Start with a guess, called `g`, and if `g*g` is close enough to `x`, then I can stop and say `g` is the answer.  Otherwise, we're going to create a new guess by taking `g` and `x/g` and averaging the two together.  
> 2. Repeat this process until you've arrived at a solution.  

This gives a little algorithm!  I.e., you start with a guess, check to see if your guess is close enough, and repeat if not.  

| `g` | `g*g` | `x/g` | `(g+x/g)/2` |
| --- | --- | --- | --- |
| 3 | 9 | 5.333 | 4.1667 |
| 4.1667 | 17.36 | 3.837 | 4.0035 |
| 4.0035 | 16.0277 | 3.997 | 4.000002 |

In this table, you can see how the algorithm converges on the square root of 16, which is 4, of course.  

---
### What is a recipe?
---

There are three pieces to an algorithm:
1. sequence of simple steps
2. flow control process
    - a process that specifies the order in which each step is executed
3. means of determining when to stop

---
---
## 1.2 Machines

So, computers are machines.  How do we capture a "recipe" inside a mechanical process?

Consider again the task of computing square roots: historically, there were two choices here:
- **fixed program** computer
    - machine designed to calculate a particular computation
        - calculator
        - Turing's Bombe (made out of vacuum tubes and relays, this machine decrypted German military communications that had been encrypted using the Enigma machine in WWII)
- **stored program** computer
    - machine stores and executes instructions
    - can load into it that description/sequence of instructions/recipe
        - then, inside the machine, there are going to be a set of parts that are going to execute those instructions when we ask them to
        - in particular, there's a specal program called the interpreter that's going to walk through each instruction in sequence, thus completing the computation we want

The advantage of the stored program computer is, of course, the ability to load in a different program for execution.  In essence, the stored program computer is emulating or imitating a fixed program computer for each program we load.  This gives us an infinite range of things to be able to do with our machine.  

With that in mind, what we want to think about is this: how do we take a description of a process (those mechanical steps) and write it in such a way that we can load it into the computer and have it do the work for us?

Before we do that, we need to think about what's inside the machine...

---
### Basic machine architecture
---

Basic machine architecture is comprised of a few simple pieces:
- memory
    - places in which we're going to store things
        - could be data, but it could also be the sequences of instructions that are our programs, our mechanical sets of steps
- input/output
    - a way to load things into the machine and print things out of it
- two elements to the "heart" of the machine
    - ALU: arithmetic logic unit
        - takes info from memory; reads it in (often two pieces of info if we're going to do an operation that takes two inputs) to do primitive operations; and, subsequently, store stuff back up in memory (typically)
        - to make that happen, we also need the following piece(s):
    - control unit
        - keeps track of what specific operation we want to do in that ALU at each point in time
        - contains an important thing called a program counter
            - when we load a program into the machine (the sequence of instructions in memory), the program counter points to the location of the first instruction
            - when we then ask the machine to execute, the program counter reads that first instruction, causes an operation to take place, and then increments the program counter, which in turn takes it to the next instruction in the sequence to do another operation, moving things back into memory, and increment the counter again
            - eventually, we're going to arrive at a true/false test
                - based on that, we're going to change the program counter to go back up, for example, to the beginning of the code

This, in essence, is what happens inside a modern machine.  Our goal now is to figure out how to write the sequence of instructions so that the computer can do the things I want it to.  

---
### To summarize...
---

> a stored program computer is a sequence of instructions stored inside the computer
- built out of simple, primitive arithmetic and logic operations
    - arithmetic and logic
    - simple tests
    - moving data

> a special program called the **interpreter** executes each instruction in order
- use tests to change flow of control through sequence
- stops when done

---
### Basic primitives
---

Most machines come with simple arithmetic and logic operations, but we might be surprised at how far this can take us.  
Alan Turing proved that you can compute anything computable with just six primitive operations.  
- Turing machine
    - consists of an infinite tape with a set of squares on it
        - in each square, there's a symbol that could represent either a 1 or 0
        - primitives it uses to compute anything computable are:
            - move left
            - move right
            - scan
            - print
            - erase
            - do nothing

Modern programming languages, thankfully, come with a more convenient set of primitives.  Nonetheless, the fundamental idea that you can compute anything with a simple set of operations remains as true as ever.  

Now, we don't want to write everything in terms of arithmetic and logic.  Rather what we're hoping to do is write descriptions (like the square root program we saw earlier) and *abstract* them, treating as if they were primitive operations thereafter.

Another fundamental property of computability that we should touch on is the fact that anything computable in one language is computable in any other programming language.  In some languages, it might be easier to do one thing compared to another—it is, by design, quite easy to manipulate matrices in MATLAB, for instance—but this does not change the fact that any **Turing complete language** is able compute the same things.  

**Turing complete** is a fundamental of computer science.  

---
---
## 1.3 Languages

So, knowing we want to create a generic recipe and knowing a bit more about what's inside the machine, we want to now go from a description of a process to a specific set of statements that we can store in the machine so that the interpreter, the evaluator, can then run those operations to use the primitives inside the machine to do the work for us.  

---
### Creating recipes
---

As we said, the programming language is going to come with a set of primitive operations, and the next step is to think about how we put them together.  To do that, we use something called an **expression**.  

Expressions
: complex but legal combinations of primitives that the programming language will recognize

Any legal expression in a programming language, any computation, has associated with it a value.  That *value* is the *meaning* of the expression.  That's going to be important, in part because we want to know how we get to that value if we know what we want to get from a particular computation—i.e., how we back out of that sequence of steps the expressions that are going to compute it for us.  

---
### Aspects of languages
---

Every programmng language can be thought of as:
1. consisting of a set of primitives
2. means of combination (ways of putting those primitives together to create new expressions)
3. means of abstraction (ways of taking some complex expression and treating it as if it were a primitive)

So, let's think about an analogy to a natural language like English.  In English, what are the primitive constructs?  
They're words—lots of them, with some being more common than others.  

In a programming language, primitive constructs are the "atoms" on which we're going to build things:
- numbers
- strings
- sequences of characters
- simple, built-in operations (like addition/subtraction, multiplication/division)

Just as with natural languages, when we put primitives together, we have to think about two different parts:
1. syntax
2. semantics

> Syntax
: parsing of a sentence to know whether or not a sentence is legal (some combinations being legal while others are not)
- In English:  
"cat dog boy" doesn't mean anything and isn't syntactically valid (as there is no verb)  
"cat hugs boy" *is* syntactically valid  

- In programming languages:  
`"hi"5` is not syntactically valid  
`3.2*5` *is* syntactically valid  

> *Static* semantics
: tells us which syntactically valid strings have meaning  
- In English:  
"I are hungry" is syntactically valid, but has a static semantic error  

- In programming languages:  
`3+"hi"` is a static semantic error  

So, we have to distinguish between things that are not statically semantically valid because they're not going to be the expressions to which we want to try to assign meaning.  

> Semantics
: the meaning associated with a syntactically correct string of symbols with no static semantic errors  
- In English, expressions can be interpreted to have many meanings  

- In programming languages, expressions have only one meaning, but may not be what the programmer intended (this is where bugs can occur)

---
### Where things can go wrong
---

- **syntactic errors**
    - common and easily caught
    - most good programming languages or the environments that interpret them will catch these directly
- **static semantic errors**
    - some languages check for these before running a program
    - can cause unpredictable behaviors
- no semantic errors, but **different meaning than what the programmer intended**
    - program crashes
    - program runs forever
    - program gives an answer, but different from expected results

---
### Our goals
---

- learn the syntax and semantics of a programming language (Python, of course!)
- learn how to use those elements to translate "recipes" for solving a problem into a form that the computer can use to do the work for us
- learn patterns and computational modes of thinking to enable us to leverage a suite of methods to solve complex problems
    - different styles of solving problems, as those styles are going to be common and easily reused when we see a new problem that fits into the same category

---
### Recap
---

Syntax
: determines whether a string is legal

Static semantics
: determines whether a string has meaning

Semantics
: assigns a meaning to a legal sentence

---
---
## 1.4 Types

Now that we have an idea of how to put together expressions by combining primitives in legal ways, we can start capturing algorithms!

---
### Python programs
---

> a program is a sequence of definitions and commands  
- **definitions** are *evaluated*  
    - ways of either assigning names to values or creating procedures to be treated as primitives  
- **commands** are *executed* by the Python interpreter 
    - statements that instruct the interpreter to do something
        - i.e. simpler expressions that we can execute directly within Python using a **shell**
    - can be typed directly into a shell or stored in a file to be read to the shell and evaluated when we choose

> **Shell**
: simply a window into which we can type expressions while the interpreter "listens" for them

Inside the shell...
- expressions are passed into the interpreter
    - it follows the set of instructions we outline to figure out what the semantics are (the meaning associated with that expression)
        - a result is subsequently printed out

> **Commands**
: could simply be an arithmetic operation, or could apply a primitive that we created to do some work for us

---
### Objects
---

- programs manipulate **data objects**
    - ...in order to get out parts of those objects or to do something with those objects

- objects have **types** that define the kinds of things programs can do to/with them
    - i.e. the type tells programs whether they can act on objects or not in a given context
        - for example: if a program is expecting a number and instead gets a string, it's not going to try to do anything with it

- objects are either:
    - **scalar**
        - cannot be subdivided
            - `int` represents **integers**
                - ex. `5`
            - `float` represents **real numbers**
                - ex. `3.14159`
            - `bool` represents **Boolean** values
                - `True` and `False`
                    - important for **tests**
            - `NoneType`
                - **special** type that has **one value**: `None`
            - there are a couple more scalar types that we'll see later on  
    - **non-scalar**
        - have internal structure that can be accessed

- can use `type()` to see the type of an object:  
```python
In [1]: type(5)
Out [1]: int

In [2]: type(3.0)
Out [2]: float
```

---
### Type conversions (cast)
---

If we want to change types, which can often happen with numbers, we can **convert an object of one type to another**:
- `float(3)` converts integer `3` to the float `3.0`
- `int(3.14159)` *truncates* the float down to the integer `3` (please note this is **not** rounding to the nearest integer)

Knowing these types, we can start putting some things together...  

---
### Printing to console
---

Here's a legal expression:  
`3+2`  
This has a value associated with it.  Perhaps obviously, the expression is to take the `3` and the `2` and apply the arithmetic operation of addition to them.  
When we evaluate it, it simply *returns* `5`.  

Makes sense, right?  
Sometimes, however, we might not want a *return* value, but rather just have something printed out for us.  
Typing `print`, which controls output to the console (in this case, saying, "print 3 plus 2"), is a little different in that *no value is **returned***.  

> `print` *returns* the `NoneType` object

What's the difference here, you might ask?  What we're going to see is that, when we're in the middle of a computation and wanting to print something out from the shell, we can use a `print` command to do so.  If we were instead to *return* the value, that value then goes back into the computation to be used for the next step.  

> I.e., in the *first* case, the whole value of the computation was 3 plus 2 equals 5.  
> In the *second* case, the ***side effec**t* is to print something while the *value returned* is nothing.  

---
### Expression
---

To combine objects and operators into expressions, we use a standard form.  The syntax is simply an object, an operator, and another object.  

`<object><operator><object>`  

*Any* expression like this that is syntactically valid has a **value**, which itself is a **type**.  

---
### Operators on `int`s and `float`s
---

| | | |
| --- | --- | --- |
| `i+j` | the **sum** | if `i` and `j` are `int`s, result is `int`; if either or both are `float`s, the result is `float` |
| `i-j` | the **difference** | ^ |
| `i*j` | the **product** | ^ |
| `i/j` | **division** | result is `float` |
| `i//j` | **int division** (floor division) | result is `int` (quotient without remainder) |
| `i%j` | the **remainder** | |
| `i**j` | `i` **to the power of** `j` | |

---
### Simple operations
---

Parentheses are used to tell Python the order of operations (innermost parentheses being evaluated first).  
- `3*5+1` evaluates to `16`
- `3*(5+1)` evaluated to `18`

**Operator precedence** without parentheses:
- `**`
- `*`
- `/`
- `+` and `-` executed left to right as they appear in the expression

---
---
## 1.5 Variables

*Abstraction* (in one form)
: giving things names so that we can refer to a value by that name and reuse it as needed  

This is the first form of abstraction that we will see.  

---
### Binding variables and values
---

- the **equal** sign is an **assignment** of a variable to a name
    - ex. `pi = 3.14159`
    - ex. `pi_approx = 22/7`
- value stored in computer's memory (in a **name table**)
- assignment **binds** name to value
- retrieve value associated with name or variable by invoking the name (i.e., typing/using `pi`)

---
### Abstracting expressions
---

Why give names to expressions?  
- want to reuse the name and not have to redo the computation to get the value
- gives us code that's much easier to understand because the names we choose to use ought to be informative
    - lets us think about what we want it to represent
- easier to change the code later if we've just got a name, as we can change the binding to the name and reuse it

```python
# notice how we are making sense of what it is we're doing with the choice of variable names
pi = 3.14159
radius = 2.2
# area of a circle
area = pi*(radius**2)
```

---
### Changing bindings
---

- can **re-bind** variable names using a new assignment statement
- previous value may still be stored in memory, but we've lost the handle (the way to "get" to it) in reassigning
- value for area does not change until we tell the computer to do the calculation again:  

```python
pi = 3.14
radius = 2.2
area = pi*(radius**2)
radius = radius + 1
# last step increments the radius, but area ends up unchanged as we have not calculated it again using the incremented radius
# this is because we are simply following the sequence of instructions as it is laid out
```

```python
# same code, but alternate method for incrementing radius shown
pi = 3.14
radius = 2.2
area = pi*(radius**2)
radius += 1
```

---
---
## 1.6 Operators and branching

So far, we've explored arithmetic operations, but the next piece of the programming puzzle we'll add in is the ability to make decisions based on **tests**.  
For that, we need to be able to *compare* things.  

Are we close enough to the square root that we're done (in the case of Heron of Alexandria's algorithm)?  Are we close enough to something else in another algorithm's implementation?  

---
### Comparison operators on `int` and `float` types
---

| `i` and `j` are any variable names: | |
| --- | --- |
| `i > j` | `i` greater than `j` |
| `i >= j` | `i` greater than **or** equal to `j` |
| `i < j` | `i` less than `j` |
| `i <= j` | `i` less than **or** equal to `j` |
| `i == j` | **equality** test—`True` if `i` equal to `j` |
| `i != j` | **inequality** test—`True` if `i` *not* equal to `j` (referred to as bang equal) |

---
### Comparison operators on `bool` type
---

| `a` and `b` are any variable names |  |
| --- | --- |
| `not a` | `True` if `a` is `False` |
|  | `False` if `a` is `True` |
| `a and b` | `True` if both are `True` |
| `a or b` | `True` if either or both are `True` |

---
### Branching programs
---

- the simplest branching statement is called a **conditional**, and is comprised of:
    - a test (expression that evaluates to `True` or `False`)
    - a block of code to execute if the test is `True`
    - an optional block of code to execute if the test is `False`

---
### Simple example
---

```python
x = int(input('Enter an integer: '))
if x%2 == 0:                            # test
    print('\nEven')                     # true block
else:
    print('\nOdd')                      # false block
print('Done with conditional!')
```

This is an example of an **if-else** statement.  It has a `True` block and a `False` block.  
Notice how **indentation** delineates blocks.  Indentation provides a visual structure that reflects the semantic structure of the program.  

---
### Nested conditionals
---

```python
x = int(input('Enter an integer: '))
if x%2 == 0:                                    # test 1
    if x%3 == 0:                                # nested test (test 1 true block)
        print('\nDivisible by 2 and 3')         # nested test true block
    else:
        print('\nDivisible by 2 and not by 3')  # nested test false block

elif x%3 == 0:                                  # test 2
    print('\nDivisible by 3 and not by 2')      # test 2 true block
```

---
### Compound Booleans
---

We can use one or more else-if statements to create a sequence of tests in whatever order we choose.  

```python
if x < y and x < z:             # test 1
    print('x is the least')
elif y < z:                     # additional test to be run if test 1 evals is false
    print('y is the least')
else:
    print('z is the least')
```

---
### Control flow: branching
---

In the following examples of branching structures:  
- `<condition>` has a value, `True` or `False`
- evaluate expressions in a given block if `<condition>` is `True`
    - note that `elif` blocks are evaluated if and when the initial `if` conditional is `False`

```python
if <condition>:
    <expression>
    <expression>
    ...
```

```python
if <condition>:
    <expression>
    <expression>
    ...
else:
    <expression>
    <expression>
    ...
```

```python
if <condition>:
    <expression>
    <expression>
    ...
elif <condition>:
    <expression>
    <expression>
    ...
else:
    <expression>
    <expression>
    ...
```

---
### What have we added?
---

- branching programs allow us to make choices to do different things based on conditions we set
- it is still the case that, at most, each statement gets executed once
    - so the maximum time to run a program depends only on the length of the program
- these programs are *linear* and run in **constant time**

---